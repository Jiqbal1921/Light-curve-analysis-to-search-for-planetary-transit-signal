# -*- coding: utf-8 -*-
"""light_curve_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GQYxUVwB0XjTr7Je8X9hXdRHxbrbwn86
"""

# light_curve_analysis.py

# Import these libraries
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from astropy.timeseries import BoxLeastSquares
from astropy.stats import sigma_clip
from scipy.signal import savgol_filter
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# Load light curves from the directory
def load_light_curves(directory):
    light_curves = {}
    for filename in os.listdir(directory):
        if filename.endswith('.dat'):  # Check for .dat files
            file_path = os.path.join(directory, filename)
            # Read the .dat file assuming it's space-separated
            light_curves[filename] = pd.read_csv(file_path, sep='\s+', comment='#')
            print(f"File: {filename}")
            print(light_curves[filename].head())  # Print the first few rows to inspect the columns
    return light_curves

# Preprocess and cleaning the light curve data
def preprocess_light_curve(data):
    # Extract time and flux
    time = data.iloc[:, 0].values  # BJD_TDB (time)
    flux = data.iloc[:, 1].values  # rel_flux_T1_dn (flux)

    # Remove NaN values or zero/negative flux values
    mask = np.isfinite(flux) & (flux > 0)
    time = time[mask]
    flux = flux[mask]

    # Sigma clipping to remove outliers
    flux_clipped = sigma_clip(flux, sigma=3)

    # Check if there are enough data points after clipping
    if np.count_nonzero(~flux_clipped.mask) < 5:
        print("Not enough data points after clipping.")
        return None, None

    # Normalize the flux
    flux_normalized = flux_clipped.data / np.median(flux_clipped.data)

    # Detrending using polynomial fitting
    poly_degree = 3  # Adjust the degree as needed
    poly_features = PolynomialFeatures(degree=poly_degree)
    time_reshaped = time.reshape(-1, 1)  # Reshape for polynomial regression
    model = LinearRegression()

    # Fit the polynomial model to the normalized flux
    model.fit(poly_features.fit_transform(time_reshaped), flux_normalized)
    detrended_flux = flux_normalized - model.predict(poly_features.fit_transform(time_reshaped))

    # Check if we have enough data points to apply the smoothing
    if len(detrended_flux) < 51:
        print("Not enough data points to apply smoothing.")
        return None, None

    # Smooth the light curve using Savitzky-Golay filter to reduce noise
    flux_smooth = savgol_filter(detrended_flux, window_length=51, polyorder=2)

    return time, flux_smooth

# Function to search for transits using Box Least Squares (BLS)
def search_transit(time, flux):
    # Define the period search space (in days)
    periods = np.linspace(0.5, 10, 10000)  # Adjust range and number of periods based on expected transit duration
    bls = BoxLeastSquares(time, flux)

    # Run the BLS search
    result = bls.power(periods, 0.1)  # 0.1 is the expected duration of the transit in days (adjust if necessary)

    # Find the best-fit period (the one with the highest power)
    best_index = np.argmax(result.power)
    best_period = result.period[best_index]
    transit_time = result.transit_time[best_index]
    duration = result.duration[best_index]

    # Compute the transit model
    transit_model = bls.model(time, best_period, duration, transit_time)

    print(f"Best-fit period: {best_period:.4f} days")
    return best_period, result, transit_model

# Function to plot the light curve and the detected transit
def plot_light_curve(time, flux, transit_model):
    plt.figure(figsize=(10, 6))

    # Plot original light curve
    plt.plot(time, flux, marker='o', linestyle='-', color='b', label='Observed Data')

    # Plot transit model on top of the light curve
    plt.plot(time, transit_model, color='r', label='Transit Model')

    plt.xlabel('BJD_TDB (Julian Date)')
    plt.ylabel('Flux (Normalized)')
    plt.title('Light Curve with Detected Transit')
    plt.grid(True)
    plt.legend()
    plt.show()

# Main function to process the light curves in a specified directory
def process_light_curves(directory):
    light_curves = load_light_curves(directory)

    # Process each light curve file
    for file_name, data in light_curves.items():
        print(f"\nProcessing {file_name}...")

        # Preprocess the light curve data
        time, flux = preprocess_light_curve(data)

        # Check if the data is valid before proceeding
        if time is None or flux is None:
            print("Skipping this light curve due to insufficient data.")
            continue

        # Search for transit events
        best_period, result, transit_model = search_transit(time, flux)

        # Plot the light curve with the detected transit model
        plot_light_curve(time, flux, transit_model)

# Specify the directory containing the light curve files
if __name__ == "__main__":
    directory = 'path_to_your_light_curve_directory'  # Change this to your local directory
    process_light_curves(directory)